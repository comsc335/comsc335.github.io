{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d361eb94",
   "metadata": {},
   "source": [
    "(activity6)=\n",
    "\n",
    "# Activity 6: Holdout and model evaluation\n",
    "\n",
    "**2026-02-12**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471dd0d1",
   "metadata": {},
   "source": [
    "# Imports and previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67472bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_hat: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Root mean squared error.\"\"\"\n",
    "    assert y_hat.shape == y.shape\n",
    "\n",
    "    # TODO: compute the RMSE, using the functions we practiced on WS 1\n",
    "    return np.sqrt( np.mean( (y_hat - y)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1e937",
   "metadata": {},
   "source": [
    "Below are implementations of the models we've built so far:\n",
    "\n",
    ":::{tip}\n",
    "\n",
    "If you click on arrow near the blue bar at the top of the heading, you can collapse the code which can help organize the notebook.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanRegressor(BaseEstimator):\n",
    "    \"\"\"Simple model that predicts the mean of the training data.\"\"\"\n",
    "\n",
    "    # constructors in Python are defined using the `__init__` method\n",
    "    # A quirk of Python OOP: the first argument is always `self`, which refers to the object itself\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # fit method trains the model on the given data, and always takes X and y as arguments\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fits the mean regressor to the training data.\n",
    "\n",
    "        Args:\n",
    "            X: the data examples of shape (n, p)\n",
    "            y: the answers vector of shape (n,)\n",
    "\n",
    "        Returns:\n",
    "            self: the fitted model\n",
    "        \"\"\"\n",
    "        # fitted model parameters are stored in `self` as instance variables and suffixed with `_`\n",
    "        self.mean_ = np.mean(y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # predict method makes predictions on new data, and always takes X as an argument\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the values for new points X.\n",
    "\n",
    "        This model will only predict the mean value of the fitted data for all new points.\n",
    "\n",
    "        Args:\n",
    "            X: the new points of shape (n_new, p)\n",
    "\n",
    "        Returns:\n",
    "            the predicted values of shape (n_new,)\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = []\n",
    "\n",
    "        \n",
    "        for x in X:\n",
    "            predictions.append(self.mean_) \n",
    "\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2167ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_nearest_indices(x: np.ndarray, X_train: np.ndarray, k: int) -> list:\n",
    "    \"\"\"Finds the indices of the k nearest neighbors to a new point x.\n",
    "    \n",
    "    Args:\n",
    "        x: the new point of shape (m,)\n",
    "        X_train: the training data of shape (n, m)\n",
    "        k: the number of nearest neighbors to find\n",
    "\n",
    "    Returns:\n",
    "        the indices of the k nearest neighbors to x in X_train\n",
    "    \"\"\"\n",
    "    dists = np.sqrt(np.sum((X_train - x)**2, axis=1))\n",
    "    sorted_indices = np.argsort(dists)\n",
    "    return sorted_indices[:k]\n",
    "\n",
    "\n",
    "# Our KNNRegressor class extends the BaseEstimator class\n",
    "class KNNRegressor(BaseEstimator):\n",
    "    \"\"\"KNN regressor model.\"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, n_neighbors: int):\n",
    "        \"\"\"Initializes the KNN regressor model.\n",
    "        \n",
    "        Args:\n",
    "            n_neighbors: the number of neighbors to use for the KNN regressor\n",
    "        \"\"\"\n",
    "\n",
    "        # self.var_name is an instance variable that can be accessed by any method in the class\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        \"\"\"Fits the KNN regressor to the training data.\n",
    "\n",
    "        Note that KNN models do not have any functions or features that need to be fit, \n",
    "        so all this method does is store the training data as instance variables.\n",
    "\n",
    "        Args:\n",
    "            X: the feature matrix of shape (n, m)\n",
    "            y: the target vector of shape (n,)\n",
    "\n",
    "        Returns:\n",
    "            self: the fitted model\n",
    "        \"\"\"\n",
    "\n",
    "        # Use self to store the training data in the instance variables\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predicts the values of a set of new points X.\n",
    "\n",
    "        Args:\n",
    "            X: the new points of shape (n_new, m)\n",
    "\n",
    "        Returns:\n",
    "            the predicted values of shape (n_new,)\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.X_.shape[1] == X.shape[1], \"X must have the same number of features as the training data\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        # this loops over the rows of X\n",
    "        for x in X:\n",
    "            # Find the k nearest neighbors to x\n",
    "            k_nearest_indices = find_k_nearest_indices(x, self.X_, self.n_neighbors)\n",
    "\n",
    "            # Compute the average of the k nearest neighbors, append to predictions\n",
    "            predictions.append(np.mean(self.y_[k_nearest_indices]))\n",
    "\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is called \"simple\" as a statistical term for one feature, not because it's simple to implement\n",
    "class SimpleLinearRegression(BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        # There are no (hyper)parameters to set\n",
    "        pass\n",
    "\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        \"\"\"Fit the model to training data.\n",
    "\n",
    "        Args:\n",
    "            X: a 2D numpy array of shape (n, 1)\n",
    "            y: a 1D numpy array of shape (n,)\n",
    "\n",
    "        Returns:\n",
    "            self: the fitted model\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        n = X.shape[0]\n",
    "        x = X.flatten()\n",
    "        # NOTE: we need to be super careful about the shape of the arrays!\n",
    "        self.w1_ = (n * np.sum(x * y) - np.sum(x) * np.sum(y)) / (n * np.sum(x**2) - (np.sum(x) ** 2))\n",
    "        self.w0_ = np.mean(y) - self.w1_ * np.mean(x)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict on new data.\n",
    "\n",
    "        Args:\n",
    "            X: a 2D numpy array of shape (n_new, 1)\n",
    "\n",
    "        Returns:\n",
    "            y_hat: a 1D numpy array of shape (n_new,)\n",
    "        \"\"\"\n",
    "        return self.w0_ + self.w1_ * X.flatten()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58232d6",
   "metadata": {},
   "source": [
    "# Part 1: train/test holdout split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de755c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "housing_df = pd.read_csv(\"~/COMSC-335/data/housing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO examine the first few rows and last few rows of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57354887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get the column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get the number of rows and columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814ab02",
   "metadata": {},
   "source": [
    "The features we have are:\n",
    "\n",
    "- `MedInc`:        median income in block group\n",
    "- `HouseAge`:      median house age in block group\n",
    "- `AveRooms`:      average number of rooms per household\n",
    "- `AveBedrms`:     average number of bedrooms per household\n",
    "- `Population`:    block group population\n",
    "- `AveOccup`:      average number of household members\n",
    "- `Latitude`:      block group latitude\n",
    "- `Longitude`:     block group longitude\n",
    "\n",
    "The answer we want to predict is:\n",
    "- `MedHouseVal`: median house value in $100,000s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4252bf9",
   "metadata": {},
   "source": [
    "Single columns in pandas can be accessed with the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing_df[\"HouseAge\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa5cfe",
   "metadata": {},
   "source": [
    "Multiple columns can be accessed with a list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_df[[\"AveRooms\", \"HouseAge\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052fb3b8",
   "metadata": {},
   "source": [
    "There are many ways to select rows from a pandas DataFrame. Similar to numpy, we can use square brackets and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab215c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first 1000 rows\n",
    "housing_df[:1000]\n",
    "\n",
    "# select the last 1000 rows\n",
    "housing_df[-1000:]\n",
    "\n",
    "# select the rows starting at index 1000\n",
    "housing_df[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a2926",
   "metadata": {},
   "source": [
    "Let's split the data into training and test sets. We'll use the **first** 80% of the data for training and the **last 20%** for testing. Complete the code below to create the `X_train`, `X_test`, `y_train`, and `y_test` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO split the data into training and test sets\n",
    "housing_train = None\n",
    "housing_test = None\n",
    "\n",
    "# TODO what are some assertions we can do to test our splits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533badb",
   "metadata": {},
   "source": [
    "Columns can also be removed with the [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the y column\n",
    "X_train = housing_train.drop(columns=[\"MedHouseVal\"])\n",
    "X_test = housing_test.drop(columns=[\"MedHouseVal\"])\n",
    "\n",
    "# save the y column\n",
    "y_train = housing_train[\"MedHouseVal\"]\n",
    "y_test = housing_test[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945275f5",
   "metadata": {},
   "source": [
    "# Part 2: Feature exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d5e43",
   "metadata": {},
   "source": [
    "Seaborn is a high-level plotting library that has strong integration with pandas DataFrames. For a given plot, we often specify the following parameters:\n",
    "\n",
    "- `x`: the column name of the x-axis\n",
    "- `y`: the column name of the y-axis\n",
    "- `data`: the pandas DataFrame to plot\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "Remember that we should only be looking at the training data when exploring the relationships between features and the target!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e94fe",
   "metadata": {},
   "source": [
    "We'll visualize the data using [sns.scatterplots](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a576dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots HouseAge vs MedHouseVal\n",
    "# alpha controls the transparency of the points\n",
    "sns.scatterplot(x=\"HouseAge\", y=\"MedHouseVal\", data=housing_train, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37111d",
   "metadata": {},
   "source": [
    "The features we have are:\n",
    "\n",
    "- `MedInc`:        median income in block group\n",
    "- `HouseAge`:      median house age in block group\n",
    "- `AveRooms`:      average number of rooms per household\n",
    "- `AveBedrms`:     average number of bedrooms per household\n",
    "- `Population`:    block group population\n",
    "- `AveOccup`:      average number of household members\n",
    "- `Latitude`:      block group latitude\n",
    "- `Longitude`:     block group longitude\n",
    "\n",
    "The answer we want to predict is:\n",
    "\n",
    "- `MedHouseVal`: median house value in $100,000s\n",
    "\n",
    "In groups of 2-3 around you, split up the features to plot on the x-axis, always keeping the y-axis as `MedHouseVal`. Compare plots to discuss what the \"best\" 2-3 features for predicting `MedHouseVal` are, and vote for them in the PollEverywhere:\n",
    "\n",
    "https://pollev.com/tliu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your scatterplots here\n",
    "sns.scatterplot(x=\"TODO\", y=\"MedHouseVal\", data=housing_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e144a0d",
   "metadata": {},
   "source": [
    "# Part 3: Model evaluation and benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be8f4b",
   "metadata": {},
   "source": [
    "Let's now fit a `MeanRegressor` model as a baseline for us to benchmark our other models against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this to change the features we're using\n",
    "feats_to_include = [\"HouseAge\"]\n",
    "\n",
    "# initialize the model\n",
    "regressor = MeanRegressor()\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(X_train[feats_to_include].to_numpy(), y_train.to_numpy())\n",
    "\n",
    "# make predictions on both the training and test sets\n",
    "y_hat_train = regressor.predict(X_train[feats_to_include].to_numpy())\n",
    "y_hat_test = regressor.predict(X_test[feats_to_include].to_numpy())\n",
    "\n",
    "# compute the RMSE\n",
    "rmse_train = rmse(y_hat_train, y_train)\n",
    "rmse_test = rmse(y_hat_test, y_test)\n",
    "\n",
    "# Rounds the RMSE to 2 decimal places\n",
    "print(f\"MeanRegressor RMSE on training set: {rmse_train:.2f}\")\n",
    "print(f\"MeanRegressor RMSE on test set: {rmse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb013b5",
   "metadata": {},
   "source": [
    "Now, let's go model-hunting: find a model that beats the MeanRegressor RMSE (lower is better) on the test set. Copy the cell above and modify it to try new model and feature combinations:\n",
    "\n",
    "- `KNNRegressor`: try different values of `n_neighbors`\n",
    "- `SimpleLinearRegression`: try different features, but note that this model only takes in 1 feature\n",
    "- `LinearRegression`: try different feature combinations\n",
    "\n",
    "Again, you can discuss with folks around you on a strategy to search through models. \n",
    "\n",
    "As you try new models and features, discuss with folks around you any discrepancies you see between the training and test set RMSEs. Is one number usually higher than the other?\n",
    "\n",
    "After trying out a few models with your group, submit your best test set RMSE rounded to 2 decimal places to the PollEverywhere:\n",
    "\n",
    "https://pollev.com/tliu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
