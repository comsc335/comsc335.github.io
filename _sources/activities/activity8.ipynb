{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "(activity8)=\n",
    "\n",
    "# Activity 8: Classification predictions and gradients\n",
    "\n",
    "**2026-02-24**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "# Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from palmerpenguins import load_penguins\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Palmer Penguins and filter to Adelie vs Chinstrap\n",
    "df = load_penguins()\n",
    "penguin_df = df[df[\"species\"].isin([\"Adelie\", \"Chinstrap\"])].dropna(subset=[\"bill_length_mm\", \"bill_depth_mm\"])\n",
    "\n",
    "# Features: bill_length_mm and bill_depth_mm\n",
    "X_train = penguin_df[[\"bill_length_mm\", \"bill_depth_mm\"]].values\n",
    "feature_names = [\"bill_length_mm\", \"bill_depth_mm\"]\n",
    "\n",
    "# Labels: Adelie = 0, Chinstrap = 1\n",
    "y_train = (penguin_df[\"species\"] == \"Chinstrap\").astype(int).values\n",
    "\n",
    "print(f\"Number of examples: {len(y_train)}\")\n",
    "print(f\"Number of Adelie (y=0): {np.sum(y_train == 0)}\")\n",
    "print(f\"Number of Chinstrap (y=1): {np.sum(y_train == 1)}\")\n",
    "print(f\"Feature matrix shape: {X_train.shape}\")\n",
    "\n",
    "penguin_df['y'] = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-header",
   "metadata": {},
   "source": [
    "# Part 1: Linear decision boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708344c",
   "metadata": {},
   "source": [
    "The above cell loads in our data into `penguin_df`.\n",
    "\n",
    "Let's visualize our two features, colored by species. Let's create a scatterplot with:\n",
    "\n",
    "- `x=\"bill_length_mm\"`\n",
    "- `y=\"bill_depth_mm\"`\n",
    "- `hue=\"species\"`\n",
    "- `data=penguin_df`\n",
    "- `alpha=0.6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scatter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=\"bill_length_mm\", \n",
    "    y=\"bill_depth_mm\",\n",
    "    hue=\"species\", \n",
    "    data=penguin_df,\n",
    "    alpha=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1019ec",
   "metadata": {},
   "source": [
    "Suppose that we have the following weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef07155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights for a 2D model using bill_length_mm and bill_depth_mm\n",
    "w0 = -24.5\n",
    "w1 = 1.35   # weight for bill_length_mm (x1)\n",
    "w2 = -1.9   # weight for bill_depth_mm (x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda9664",
   "metadata": {},
   "source": [
    "We can again solve for the decision boundary by setting $h=0$:\n",
    "\n",
    "$$0 = w_0 + w_1 x_1 + w_2 x_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7ef57",
   "metadata": {},
   "source": [
    "$x_2$ is on the y-axis in our plot, so we can solve for it:\n",
    "\n",
    "$$\n",
    "-w_2 x_2 = w_0 + w_1 x_1 \\quad \\Longrightarrow \\quad x_2 = -\\frac{w_0 + w_1 x_1}{w_2}\n",
    "$$\n",
    "\n",
    "Let's plot this line over our data:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c44b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two x1 endpoints to draw the boundary line\n",
    "x1 = np.array([35, 55])\n",
    "\n",
    "\n",
    "# TODO compute the corresponding x2 values on the decision boundary\n",
    "x2 = - (w0 + w1 * x1) / w2\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"bill_length_mm\", \n",
    "    y=\"bill_depth_mm\",\n",
    "    hue=\"species\", \n",
    "    data=penguin_df,\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.plot(x1, x2, color=\"black\")\n",
    "plt.ylim(15,22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a86fee",
   "metadata": {},
   "source": [
    ":::{admonition} Takeaway\n",
    "\n",
    "Even though the sigmoid function is non-linear, the decision boundary is going to be linear in the features!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fit-header",
   "metadata": {},
   "source": [
    "# Part 2: Generating probabilities and predictions\n",
    "\n",
    "[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) from scikit-learn works the same way as [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html): we call `.fit(X, y)` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO creates a LogisticRegression model and fit it on X and y\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the learned weights\n",
    "print(f\"Intercept (w0): {model.intercept_[0]:.4f}\")\n",
    "print(f\"Weights: {model.coef_[0]}\")\n",
    "print(f\"  w1 (bill_length): {model.coef_[0][0]:.4f}\")\n",
    "print(f\"  w2 (bill_depth):  {model.coef_[0][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predict-proba-header",
   "metadata": {},
   "source": [
    "But unlike `LinearRegression`, logistic regression can output probabilities using the `.predict_proba()` method:\n",
    "\n",
    "This returns an array of shape `(n, 2)` where:\n",
    "- Column 0: probability of class 0 (Adelie)\n",
    "- Column 1: probability of class 1 (Chinstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict-proba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call predict_proba() on the model with input X\n",
    "proba = None\n",
    "\n",
    "print(f\"Shape of proba: {proba.shape}\")\n",
    "print(f\"\\nFirst 5 rows of proba:\")\n",
    "print(proba[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecba6ac",
   "metadata": {},
   "source": [
    "Predictions are then made by picking the class with the highest probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call predict_proba on the model with input X\n",
    "preds = None\n",
    "\n",
    "print(f\"Shape of preds: {preds.shape}\")\n",
    "print(f\"\\nFirst 5 rows of preds:\")\n",
    "print(preds[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb622204",
   "metadata": {},
   "source": [
    "Let's look at how to compute these outputs on our own.\n",
    "\n",
    "Suppose we have the $P(y = 1)$ probabilities from the slides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbb2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1_chinstrap = np.array([0.16, 0.78, 0.29, 0.92, 0.52])\n",
    "\n",
    "print(proba1_chinstrap)\n",
    "print(proba1_chinstrap.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65885c",
   "metadata": {},
   "source": [
    "To convert a 1D array of shape `(n,)` into a 2D array with shape `(n, 1)`, we can use [np.reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeabe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the -1 means \"infer the size of the other dimension\"\n",
    "proba1_chinstrap = proba1_chinstrap.reshape(-1, 1)\n",
    "\n",
    "print(proba1_chinstrap)\n",
    "print(proba1_chinstrap.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0ab45",
   "metadata": {},
   "source": [
    "Since we know that probabilities must sum to 1, what is the line of code that can generate the 2D array for the $P(y = 0)$ probabilities? **Hint**: recall what happens when we perform arithmetic between a number and a NumPy array.\n",
    "\n",
    "Submit the line of code here: https://pollev.com/tliu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031555d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this can be done in one line!\n",
    "proba0_adelie = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b72c7",
   "metadata": {},
   "source": [
    "[np.column_stack()](https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html) then can be used to stack arrays column-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9709be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_array = np.column_stack([proba0_adelie, proba1_chinstrap])\n",
    "\n",
    "print(proba_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791451fb",
   "metadata": {},
   "source": [
    "How do we then go from this `proba_array` to a 1D array of predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583a4a93",
   "metadata": {},
   "source": [
    "[np.argmax()](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) finds the **index** of the maximum value, and can be used with axis operations\n",
    "\n",
    "- axis=1 means: find the index of the maximum value within each row\n",
    "- axis=0 means: find the index of the maximum value within each column\n",
    "- no axis means: find the index of the maximum value in the entire array\n",
    "\n",
    "Note the shape changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b52e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proba_array)\n",
    "print(proba_array.shape)  # (n, 2)\n",
    "print(\"-----------------\")\n",
    "\n",
    "print(np.argmax(proba_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b0125",
   "metadata": {},
   "source": [
    "What axis should we use to generate predictions from `proba_array`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accuracy-header",
   "metadata": {},
   "source": [
    "# Part 3: Broadcasting practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589e8e7",
   "metadata": {},
   "source": [
    "On HW 1, we computed the gradient descent update rule \"manually\" for each of the weights:\n",
    "\n",
    "$$\n",
    "w_{1, \\text{new}} &= w_{1, \\text{old}} - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w_1} \\\\\n",
    "w_{2, \\text{new}} &= w_{2, \\text{old}} - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w_2}\n",
    "$$\n",
    "\n",
    "Today, we'll practice using broadcasting to perform a gradient update for all the weights at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808f283",
   "metadata": {},
   "source": [
    "Suppose we had some loss function $\\mathcal{L}$ such that the gradient with respect to weights $w_1, w_2, \\ldots, w_p$ is given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_j} = \\sum_{i=1}^n y_i x_{i,j}\n",
    "$$\n",
    "\n",
    "This gives the gradient update rule for all the weights:\n",
    "\n",
    "$$\n",
    "w_{j, \\text{new}} = w_{j, \\text{old}} - \\alpha \\sum_{i=1}^n y_i x_{i,j}\n",
    "$$\n",
    "\n",
    "Given the y's as a 1D array `y` of shape `(n,)`, and the data matrix `X` of shape `(n, p)`, we can compute the gradient update for all the weights at once using broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradient-demo-header",
   "metadata": {},
   "source": [
    "Let's trace through the broadcasting with a small example ($n=3$ examples, $p=2$ features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small example to show broadcasting\n",
    "X = np.array([[1, 2],\n",
    "              [2, 4],\n",
    "              [5, 6]])\n",
    "y = np.array([1, 0, 1])\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(X)\n",
    "print(\"-----------------\")\n",
    "\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fb8ac",
   "metadata": {},
   "source": [
    "Out goal is to compute the summation gradient term for all the weights simultaneously with broadcasting:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^n y_i x_{i,1} & \\sum_{i=1}^n y_i x_{i,2}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111af50",
   "metadata": {},
   "source": [
    "To do so, we multiply each feature of `X` by `y` element-wise:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1\\times1 & 1\\times2 \\\\\n",
    "0 \\times 2 & 0 \\times 4 \\\\\n",
    "1 \\times 5 & 1 \\times 6 \\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "0 & 0 \\\\\n",
    "5 & 6 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ab646",
   "metadata": {},
   "source": [
    "And then sum over the rows:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 + 0 + 5 & 2 + 0 + 6 \n",
    "\\end{bmatrix}  = \\begin{bmatrix}\n",
    "6 & 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f368e29",
   "metadata": {},
   "source": [
    "In order for `y` to broadcast with `X`, we need to reshape `y` to have shape `(3, 1)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update y to be 2D with shape (n, 1)\n",
    "y_reshaped = None\n",
    "\n",
    "print(y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give us a broadcasting error\n",
    "# y * X\n",
    "\n",
    "# TODO: use y_shaped to properly broadcast with X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a26656",
   "metadata": {},
   "source": [
    "Then, we use axis=0 to np.sum over the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e290ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO take the sum over the rows, resulting in shape (p,)\n",
    "result = None\n",
    "\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa926758",
   "metadata": {},
   "source": [
    "`result` is a 1D array with shape `(p,)`, which can be used to update all the weights at once:\n",
    "\n",
    "$$\n",
    "w_{1, \\text{new}} &= w_{1, \\text{old}} - \\alpha \\underbrace{\\sum_{i=1}^n y_i x_{i,1}}_{\\text{result[0]}} \\\\\n",
    "w_{2, \\text{new}} &= w_{2, \\text{old}} - \\alpha \\underbrace{\\sum_{i=1}^n y_i x_{i,2}}_{\\text{result[1]}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_old = np.array([0, 1])\n",
    "alpha = 0.1\n",
    "\n",
    "# TODO: all 2 weights are updated at once without a loop\n",
    "w_new = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45efb9",
   "metadata": {},
   "source": [
    "NumPy broadcasting allows this to work for any number of features $p$, and the gradient update on HW 2 will use this same technique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
