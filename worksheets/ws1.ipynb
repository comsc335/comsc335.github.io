{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca60014",
   "metadata": {},
   "source": [
    "(ws1)=\n",
    "# Worksheet 1\n",
    "\n",
    ":::{epigraph}\n",
    "Getting Started \n",
    "\n",
    "-- TODO your name here\n",
    ":::\n",
    "\n",
    "\n",
    ":::{admonition} Collaboration Statement\n",
    "- TODO brief statement on the nature of your collaboration.\n",
    "- TODO your collaborator's names here.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc69b7",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Get familiarized with the Jupyterhub interface and the course's submission system.\n",
    "- Practice with the first math concepts needed for the course:\n",
    "    - Derivatives\n",
    "    - Vectors\n",
    "    - Norms and distances\n",
    "- Practice with `numpy` array usage.\n",
    "- Learn about OOP concepts in Python with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8109e0",
   "metadata": {},
   "source": [
    "# 1. Course resources [0.5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9fb860",
   "metadata": {},
   "source": [
    "**1.1:** Read through all the pages listed in the syllabus section on the [course website](https://comsc335cd.github.io/). What are the two file types that you need to submit to Gradescope for each assignment? \n",
    "\n",
    "**Your Response**: TODO\n",
    "\n",
    "**1.2** Reply to the Course Intros thread on Ed introducing yourself and sharing why you're interested in taking this course.\n",
    "\n",
    "TODO post to the Ed discussion thread: https://edstem.org/us/courses/94030/discussion/7575488"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6a861",
   "metadata": {},
   "source": [
    "## Coding interface\n",
    "\n",
    "**Programming language: Python.** This course will be taught in Python. To get the most out of the course, it’s important you don’t feel bogged down by the syntax of the language so that you can focus on the concepts introduced. If you do not have prior experience with Python, that’s no problem. **Please do take the time at start of the course to study and practice it.**\n",
    "\n",
    "For resources, I recommend going through an online Python tutorial such as this one: https://www.learnpython.org/, and completing all the sections under \"Learn the Basics.\"\n",
    "\n",
    "**Libraries.** We will be using a standard Python machine learning stack throughout the course:\n",
    "\n",
    "- [numpy](https://numpy.org/) + [scipy](https://scipy.org/): for scientific computing\n",
    "- [sklearn](https://scikit-learn.org/): for building (non-neural network) machine learning models and pipelines\n",
    "- [pandas](https://pandas.pydata.org/): for data table manipulation and analysis\n",
    "- [seaborn](https://seaborn.pydata.org/) + [matplotlib](https://matplotlib.org/): for figure visualization\n",
    "- [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/): for interactive widgets\n",
    "- [pytorch](https://pytorch.org/): for building and training deep learning models\n",
    "- [autograd](https://github.com/HIPS/autograd/blob/master/docs/tutorial.md): for automatic differentiation (more on this later in the semester!)\n",
    "\n",
    "We will introduce the functionality of these libraries as we need them in the course, so we do not assume prior knowledge of these libraries. However, I do encourage you to refer to the documentation for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3600a1",
   "metadata": {},
   "source": [
    "**Computing environment.** We will be using Jupyter notebooks (.ipynb files) for all assignments. We have a centralized Jupyterhub server which provides a uniform environment for everyone, and you can access it anywhere on campus using your MHC credentials:\n",
    "\n",
    "- https://comsc335-sp-hub.mtholyoke.edu \n",
    "\n",
    ":::{warning}\n",
    "If you would like to run your code locally, you are welcome to do so and we can provide the necessary list of installation packages. However, note that the teaching team unfortunately cannot help troubleshoot issues with your local environment. In particular, some of the scientific computing libraries can be finnicky to install on ARM-based Macs, which is why we have centralized our Jupyterhub server.\n",
    ":::\n",
    "\n",
    "There are two types of cells in a Jupyter notebook:\n",
    "\n",
    "- Code cells: for writing and running code\n",
    "- Markdown cells: for writing text\n",
    "\n",
    "**1.3 TODO** Create a new code cell below that defines a function called `hello()` that takes no arguments and returns the string `\"Hello, COMSC 335!\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5effaa7b",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "Many of the functions we ask you to implement in the course will be autograded. There will be no submission limit, so feel free to submit multiple times to get feedback on your work!\n",
    "\n",
    "We will frequently provide some simple test cases via `assert` statements wrapped in a `if __name__ == \"__main__\":` block to check your function, like the one below. The syntax for assert statements is as follows:\n",
    "\n",
    "```python\n",
    "assert bool_expression, description\n",
    "```\n",
    "where the `bool_expression` is a boolean expression that tests some condition, and the `description` is a string that will be displayed if the assertion fails (evaluates to `False`).\n",
    "\n",
    "You are encouraged to write your own test cases as well for your functions!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # check that hello() returns the specified string\n",
    "    assert hello() == \"Hello, COMSC 335!\", \"hello() does not return the correct string\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a284af",
   "metadata": {},
   "source": [
    "Jupyter notebooks allow users to write code and text in the same file. The language used to write text is called Markdown, and is popular language for writing documentation (for example, Github README files default to Markdown).\n",
    "\n",
    "\n",
    "In particular, Markdown allows users to write mathematical notation using LaTeX. Read through [this guide](https://gtribello.github.io/mathNET/assets/notebook-writing.html) to learn how to format markdown cells with LateX, as you will be typesetting some mathematical statements in the assignments.\n",
    "\n",
    "\n",
    ":::{tip}\n",
    "\n",
    "If you double click on a cell with a math equation, you can view the LaTeX source code for the cell that you can copy and paste into your own markdown cells.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b54058",
   "metadata": {},
   "source": [
    "## Math\n",
    "\n",
    "We will be using mathematical notation to formalize many concepts in this course. For example, the notation for sums is as follows:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} x_i = x_1 + x_2 + x_3 + \\cdots + x_n\n",
    "$$\n",
    "\n",
    "which can be read as \"the sum of $x_i$'s from $i=1$ to $n$\".\n",
    "\n",
    "You may also see only a subscript underneath the summation symbol, which means the sum is over all the elements in the set. For example, the sum of all elements in the set $A=\\{1,2,3\\}$ is written as:\n",
    "\n",
    "$$\n",
    "\\sum_{x \\in A} x = 1 + 2 + 3 = 6\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797cd37",
   "metadata": {},
   "source": [
    "# 2. Calculus primer [1 pt]\n",
    "\n",
    "In this course, we will be making frequent use of derivatives for optimization. Recall from your calculus classes that the **derivative** of a function $f(x)$ points in the direction of steepest ascent of the function. The derivative is sometimes denoted as $f'(x)$ or $\\frac{d}{dx} f(x)$. Here, will use the latter notation to more closely align with the notation used for *partial derivatives* of functions with multiple inputs.\n",
    "\n",
    "Here is a list of some common differentiation rules that will be useful when brushing up on calculus:\n",
    "\n",
    ":::{admonition} Common Differentiation Rules\n",
    "\n",
    "- Constant multiple rule: \n",
    "\n",
    "$$\\frac{d}{dx} (c \\cdot f(x)) = c \\cdot \\frac{d}{dx} f(x)$$\n",
    "\n",
    "- Constant rule: \n",
    "\n",
    "$$\\frac{d}{dx} (c) = 0$$\n",
    "\n",
    "- Sum rule: \n",
    "\n",
    "$$\\frac{d}{dx} (f(x) + g(x)) = \\frac{d}{dx} f(x) + \\frac{d}{dx} g(x)$$\n",
    "\n",
    "- Product rule: \n",
    "\n",
    "$$\\frac{d}{dx} (f(x) \\cdot g(x)) = \\frac{d}{dx} f(x) \\cdot g(x) + f(x) \\cdot \\frac{d}{dx} g(x)$$\n",
    "\n",
    "- Quotient rule: \n",
    "\n",
    "$$\\frac{d}{dx} \\left( \\frac{f(x)}{g(x)} \\right) = \\frac{\\frac{d}{dx} f(x) \\cdot g(x) - f(x) \\cdot \\frac{d}{dx} g(x)}{g(x)^2}$$\n",
    "\n",
    "- Chain rule: \n",
    "\n",
    "$$\\frac{d}{dx} f(g(x)) = \\frac{d}{dx} f(g(x)) \\cdot \\frac{d}{dx} g(x)$$\n",
    "\n",
    ":::\n",
    "\n",
    "**2.1:** What is the derivative of $f(x) = 3x^2 + 2x + 5$? Typeset your answer in LaTeX below.\n",
    "\n",
    "$$\n",
    "TODO\n",
    "$$\n",
    "\n",
    "**2.2:** Using the chain rule, what is the derivative of $h(x) = (2x + 1)^3$? Typeset your answer in LaTeX below.\n",
    "\n",
    "$$\n",
    "TODO\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749d5bc",
   "metadata": {},
   "source": [
    "\n",
    ":::{admonition} Solutions (click this to check once you've completed 2.1 and 2.2)\n",
    ":class: dropdown\n",
    "\n",
    "2.1: \n",
    "\n",
    "$$\\frac{d}{dx} (3x^2 + 2x + 5) = 6x + 2$$\n",
    "\n",
    "2.2: \n",
    "\n",
    "$$\\frac{d}{dx} ((2x + 1)^3) = 3(2x + 1)^2 \\cdot \\frac{d}{dx} (2x + 1) =  3 (2x + 1)^2 \\cdot 2 = 6(2x + 1)^2$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac5b2c",
   "metadata": {},
   "source": [
    "\n",
    "## Partial derivatives\n",
    "\n",
    "Most machine learning models are functions of multiple variables. Thus, we need to extend the concept of derivatives to multiple variables, which are called **partial derivatives**.\n",
    "\n",
    "We find partial derivatives by varying one variable at a time, holding all of the other variables constant. For example, the partial derivative of a function $f(x_1, x_2)$ **with respect to** $x_1$ is found by treating $x_2$ as a constant and differentiating with $x_1$ as the variable of interest. This is denoted as:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial x_1} f(x_1, x_2)$$\n",
    "\n",
    "In general, we treat all variables except the one we are differentiating with respect to as constants.\n",
    "\n",
    "For example, suppose we have a function $f(x_1, x_2) = (x_1 + 2x_2^3)^2$. Then, the partial derivative of $f$ with respect to $x_1$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_1} f(x_1, x_2) &= 2(x_1 + 2x_2^3) \\cdot \\frac{\\partial}{\\partial x_1} (x_1 + 2x_2^3), \\text{ by the chain rule} \\\\\n",
    "&= 2(x_1 + 2x_2^3) \\cdot 1, \\text{ by the constant multiple rule, $x_2$ is treated as a constant} \\\\\n",
    "&= 2(x_1 + 2x_2^3)\n",
    "$$\n",
    "\n",
    "\n",
    "**2.3:** Compute the partial derivative of $f(x_1, x_2) = (x_1 + 2x_2^3)^2$ with respect to $x_2$.\n",
    "\n",
    "$$\n",
    "TODO\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e71eb",
   "metadata": {},
   "source": [
    "\n",
    "We may also encounter taking partial derivatives of functions over sums. For example, consider the following function:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2, \\ldots, x_p) = \\sum_{j=1}^{p} x_j^{j+1}\n",
    "$$\n",
    "\n",
    "We might want to compute the partial derivative of $f$ with respect to some $x_q$ where $q \\in \\{1, 2, \\ldots, p\\}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_q} f(x_1, x_2, \\ldots, x_p) = \\frac{\\partial}{\\partial x_q} \\sum_{j=1}^{p} x_j^{j+1}\n",
    "$$\n",
    "\n",
    " While this might look a little daunting, we can apply the rules shown so far to compute the partial derivatives. Let's do this step by step.\n",
    "\n",
    "First, we can split the summation into $p$ terms:\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} x_j^{j+1} = x_1^{2} + x_2^{3} + x_3^{4} + \\cdots + x_p^{p+1}\n",
    "$$\n",
    "\n",
    "Then, by the sum rule and the fact that all other variables are treated as constants, we can compute the partial derivative of $f$ with respect to $x_q$ as follows:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_q} \\sum_{j=1}^{p} x_j^{j+1} &= \\frac{\\partial}{\\partial x_q} (x_1^{2} + x_2^{3} + x_3^{4} + \\cdots + x_p^{p+1}) \\\\\n",
    "&= \\frac{\\partial}{\\partial x_q} x_q^{q+1} \\\\\n",
    "&= (q+1) x_q^q\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd887085",
   "metadata": {},
   "source": [
    "\n",
    "**2.4:** Consider the following function of five variables, $(w_1, w_2, w_3, w_4, w_5)$:\n",
    "\n",
    "$$\n",
    "f(w_1, w_2, w_3, w_4, w_5) = \\sum_{j=1}^{5} (w_j + 1)^2\n",
    "$$\n",
    "\n",
    "Compute the partial derivative of $f$ with respect to $w_3$.\n",
    "\n",
    "$$\n",
    "TODO\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d3f1c",
   "metadata": {},
   "source": [
    "\n",
    ":::{admonition} Solutions (click this to check once you've completed 2.3 and 2.4)\n",
    ":class: dropdown\n",
    "\n",
    "2.3: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_2} (x_1 + 2x_2^3)^2 &= 2(x_1 + 2x_2^3) \\cdot \\frac{\\partial}{\\partial x_2} (x_1 + 2x_2^3) \\\\\n",
    "&= 2(x_1 + 2x_2^3) \\cdot 6x_2^2 \\\\\n",
    "&= 12x_2^2(x_1 + 2x_2^3)\n",
    "$$\n",
    "\n",
    "2.4: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_3} \\sum_{j=1}^{5} (w_j + 1)^2 &= 2(w_3 + 1) \\cdot \\frac{\\partial}{\\partial w_3} (w_3 + 1) \\\\\n",
    "&= 2(w_3 + 1) \\cdot 1 \\\\\n",
    "&= 2(w_3 + 1)\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e680f2",
   "metadata": {},
   "source": [
    "# 3. NumPy fundamentals [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e6de6",
   "metadata": {},
   "source": [
    "## NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d72f1",
   "metadata": {},
   "source": [
    "[NumPy](https://numpy.org/) is the standard Python library for scientific computing. The standard import idiom for the library is as follows:\n",
    "\n",
    "```python\n",
    "# the standard way to import numpy\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "We can then use the `np` prefix to access the functions and classes in the library. The primary data structure in NumPy is the `ndarray`, which is a multi-dimensional array of elements of the same type, typically integers or floats.\n",
    "\n",
    "We can create an `ndarray` using the `np.array()` function and passing in Python lists. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4]) # create an array from a list\n",
    "print(type(a)) # Will print <class 'numpy.ndarray'>\n",
    "print(a) # pretty prints the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db7b7a",
   "metadata": {},
   "source": [
    " A fundamental property of a NumPy array is its **shape**, which is a tuple of integers that represent the size of the array in each dimension. For example, the shape of the array `a` is `(4,)`, which means it has 4 elements in one dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape) # Will print (4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95abc15",
   "metadata": {},
   "source": [
    "We can thus create two-dimensional arrays by passing in a list of lists to the `np.array()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates 2-row, 3-column array with a list of lists\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# the same array, but formatted for better readability\n",
    "b = np.array([[1, 2, 3], \n",
    "              [4, 5, 6]])\n",
    "\n",
    "# prints the array\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebed87",
   "metadata": {},
   "source": [
    "The shape of `b` is `(2, 3)`, which means it has 2 rows and 3 columns.\n",
    "\n",
    "The shape tuple itself provides useful information about the array and can be accessed using `[ ]` notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the first element of the shape tuple, which is the number of rows in b\n",
    "print(b.shape[0])\n",
    "\n",
    "# prints the second element of the shape tuple, which is the number of columns in b\n",
    "print(b.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4cc684",
   "metadata": {},
   "source": [
    "**3.1** Complete the function below to create an array of shape `(4, 2)` with any values you want in it.\n",
    "\n",
    ":::{admonition} Python Return Type Hints\n",
    "\n",
    "You'll notice that the function definition includes `-> np.ndarray`. This is a Python *type hint* that indicates the function returns an `np.ndarray`. These hints are not required for Python code to run, but is good practice to include in order to increase the readability of your code. They are also used by some text editors like VSCode to provide type-checking and documentation. Most of the functions you will see in this course will have type hints.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_practice() -> np.ndarray:\n",
    "    \"\"\"Practice with creating arrays of a specific shape.\n",
    "    \n",
    "    Returns:\n",
    "        A 2D array of shape (4, 2)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO your code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    result = shape_practice()\n",
    "    assert result.shape == (4, 2), \"result should be a 2D array of shape (4, 2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90579da",
   "metadata": {},
   "source": [
    "There are helper functions that can be used to create arrays with specific values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((2, 3)) # create a shape (2, 3) array with all elements equal to 0\n",
    "print(zeros)\n",
    "print(\"----\")\n",
    "ones = np.ones((4, 4)) # create a shape (4, 4) array with all elements equal to 1\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1903902",
   "metadata": {},
   "source": [
    "## Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a4df7",
   "metadata": {},
   "source": [
    "NumPy arrays can be indexed in a variety of different ways. To begin, we can access elements using square brackets. For example, we can access index 0 of `a` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the whole array\n",
    "print(a)\n",
    "\n",
    "# NumPy arrays are 0-indexed\n",
    "print(a[0]) # Will print 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d4fa9",
   "metadata": {},
   "source": [
    "Just like with Python lists, we can use negative indices to access elements from the end of the array. For example, `a[-1]` will return the last element of `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[-1]) # Will print 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9117c",
   "metadata": {},
   "source": [
    "If the array is multidimensional, we can access elements by specifying the index for each dimension. For example, we can access the element in the second row and third column of `b` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the whole array\n",
    "print(b)\n",
    "\n",
    "# Access the element in the second row and third column\n",
    "print(b[1, 2]) # Will print 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b6d62",
   "metadata": {},
   "source": [
    "NumPy arrays also support **slicing** with the colon `:` operator, which allows us to access a range of elements in the array. If a `:` is used as the index, it is interpreted as \"take all elements in this dimension\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the whole array\n",
    "print(b)\n",
    "\n",
    "# Access the first row\n",
    "print(b[0, :]) # Will print [1 2 3]\n",
    "\n",
    "# Access the second column. Note that the selection is a 1D array so there no notion of a \"column vector\" in NumPy\n",
    "print(b[:, 1]) # Will print [2 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52691259",
   "metadata": {},
   "source": [
    "The slice operator can be combined with beginning and ending indices to access a range of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24291d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the whole array\n",
    "print(b)\n",
    "\n",
    "print(\"----\")\n",
    "# Access the first two columns of row 0\n",
    "print(b[0, :2]) # Will print [1 2]\n",
    "print(\"shape of b[0, :2]:\", b[0, :2].shape)\n",
    "print(\"----\")\n",
    "\n",
    "# Access all rows and the last two columns\n",
    "print(b[:, 1:]) # Will print [[2, 3], \n",
    "#                             [5, 6]]\n",
    "print(\"shape of b[:, 1:]:\", b[:, 1:].shape)\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4ebc3",
   "metadata": {},
   "source": [
    "We need to pay attention to the shape of the array when slicing. Note how the first selection above returns a 1D array of shape `(2,)`, while the second selection returns a 2D array of shape `(2, 2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bda8af",
   "metadata": {},
   "source": [
    "**3.2:** Consider the array `c` defined in the function below. Use indexing to access `[4, 6]` from `c` and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_practice() -> np.ndarray:\n",
    "    \"\"\"Practice with indexing\"\"\"\n",
    "\n",
    "    c = np.array([[1, 3, 5], \n",
    "                  [2, 4, 6],\n",
    "                  [3, 5, 7]])\n",
    "\n",
    "    # TODO your code here\n",
    "    return None \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = index_practice()\n",
    "    assert result.shape == (2,), \"result should be a 1D array of shape (2,)\"\n",
    "    # np.allclose() checks if all elements in the array are equal to the corresponding elements in the other array\n",
    "    assert np.allclose(result, np.array([4, 6])), \"result should be [4, 6]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9b786",
   "metadata": {},
   "source": [
    "**3.3:** Complete the function below that selects the *last* column of the passed in array.\n",
    "\n",
    ":::{admonition} Python Parameter Type Hints\n",
    "\n",
    "You'll notice that function parameter name is written as `arr: np.ndarray`. Similar to the return type hint, this is a Python *parameter* type hint that indicates the function parameter `arr` is an `np.ndarray`. Again, these hints are optional and do not affect the execution of the code, but is good practice to include in order to increase the readability of Python code.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_last_column(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Select the last column of the passed in array.\n",
    "    \n",
    "    Args:\n",
    "        arr: A 2D array\n",
    "    \n",
    "    Returns:\n",
    "        A 1D array of the last column of the passed in array\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO your code here\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_arr = np.array([[1, 2], \n",
    "                         [4, 5]])\n",
    "    \n",
    "    result = select_last_column(test_arr)\n",
    "    assert np.allclose(result, np.array([2, 5])), \"result should be [2, 5]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bf34b",
   "metadata": {},
   "source": [
    "## Boolean indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98626647",
   "metadata": {},
   "source": [
    "We can also apply boolean operators to arrays. These operations return an array **of the same shape** as the original array, with elements set to `True` or `False` depending on the result of the boolean operation. For example, we can check which elements of `a` are greater than 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "print(a > 2) # Will print [False False  True  True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f2286",
   "metadata": {},
   "source": [
    "We can then use these boolean arrays to index into the original array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects the elements of a that are greater than 2\n",
    "print(a[a > 2]) # Will print [3 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9595552",
   "metadata": {},
   "source": [
    "**3.4:** Complete the function below that selects all elements of the passed in array that are even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb40cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_evens(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Select all elements of the passed in array that are even.\n",
    "    \n",
    "    Args:\n",
    "        arr: A 1D array\n",
    "    \n",
    "    Returns:\n",
    "        A 1D array of the elements of the passed in array that are even.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO your code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50885c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "    result = select_evens(test_arr)\n",
    "    assert np.allclose(result, np.array([2, 4, 6])), \"result should be [2, 4, 6]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf2638",
   "metadata": {},
   "source": [
    "## Array arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6d8df",
   "metadata": {},
   "source": [
    "Basic arithmetic operations are applied element-wise to arrays. That means that the shapes of the arrays must be the same. \n",
    "\n",
    "The following code adds two arrays element-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 1, 1])\n",
    "b = np.array([2, 4, 6])\n",
    "\n",
    "print(a + b) # Will print [3 5 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6163a0",
   "metadata": {},
   "source": [
    "We can also apply arithmetic operations to arrays with scalars (a single number). The scalar is applied to *each element* in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00833a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([2, 4, 6])\n",
    "\n",
    "print(b * 2) # Will print [4 8 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c746e7",
   "metadata": {},
   "source": [
    "**3.5** Work out what the following code will print before checking your answer.\n",
    "\n",
    "```python\n",
    "a = np.array([2, 1])\n",
    "b = np.array([-1, 1])\n",
    "\n",
    "print((a * b) - 1) \n",
    "```\n",
    "\n",
    "**Your Response**: `[TODO]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7c4bc",
   "metadata": {},
   "source": [
    ":::{admonition} Solutions (click this to check once you've completed 3.5)\n",
    ":class: dropdown\n",
    "\n",
    "The multiplication is also performed element-wise, so we get:\n",
    "\n",
    "\n",
    "`[(2*-1) - 1,  (1*1) - 1] = [-3, 0]`\n",
    "\n",
    "\n",
    "Note that this is *not* the same as matrix multiplication or a dot product. We will cover matrix manipulation and NumPy broadcasting concepts in a future worksheet.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb4da40",
   "metadata": {},
   "source": [
    "# 4. Vectors, norms, and distances [1 pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c656a97",
   "metadata": {},
   "source": [
    "As we've seen, machine learning models are functions of potentially many features. Instead of writing out the individual variables (e.g. $x_1, x_2, \\ldots, x_p$), we can collect them into a **vector** to represent them. They are often denoted as a bold-faced letter $\\mathbf{x}$ or with an arrow above the letter $\\vec{x}$. In this course, we will use the arrow notation to visually differentiate the vectors from scalars:\n",
    "\n",
    "$$\n",
    "\\vec{x} \\in \\mathbb{R}^p, \\quad \\vec{x} = (x_1, x_2, \\ldots, x_p)\n",
    "$$\n",
    "\n",
    "These vectors generalize the geometric vectors you might have seen in math courses to higher dimensions. Mapping onto the NumPy concepts we just practiced, we can think of vectors as 1D arrays of shape `(p,)`, where `p` is the number of elements (and thus the dimensionality) in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87addde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# represents a vector in 3-dimensional space\n",
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a60fa",
   "metadata": {},
   "source": [
    "## Norms\n",
    "\n",
    "Geometric vectors can be visualized as a line segment in space that starts at the origin. For example, we can represent the two-dimensional vector $\\vec{x} = (2, 3)$ as follows:\n",
    "\n",
    "![](images/geometric_vector.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec7ea9",
   "metadata": {},
   "source": [
    "We can generalize this notion of length to vectors in any number of dimensions, as well as different ways to measure the \"length\" of a vector, which is called a **norm**. Norms are represented using double vertical bars e.g. $\\|\\vec{x}\\|$, and always produce a scalar value that represents vector length. A commonly used norm is the **Euclidean norm**, which is defined as:\n",
    "\n",
    ":::{admonition} Euclidean norm\n",
    "\n",
    "$$\n",
    "\\|\\vec{x}\\|_2 = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_p^2} = \\sqrt{\\sum_{j=1}^{p} x_i^2}\n",
    "$$\n",
    "\n",
    "This is also known as the **L2 norm** (note the 2 in the subscript).\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba5b3f",
   "metadata": {},
   "source": [
    "One straightforward way to implement this is to use a for loop for the summation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_norm_slow(x: np.ndarray) -> float:\n",
    "    \"\"\"Compute the Euclidean norm of a vector using a for loop.\n",
    "    \n",
    "    Args:\n",
    "        x: A 1D array\n",
    "    \n",
    "    Returns:\n",
    "        The Euclidean norm of the vector\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        sum += x[i]**2\n",
    "\n",
    "    # Computes the square root of the sum\n",
    "    return np.sqrt(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20218c",
   "metadata": {},
   "source": [
    "However, loops are slow in Python for large inputs. NumPy provides many **vectorized** operations, which can be directly applied to arrays and are highly optimized for performance. Here, let's use the [np.sum()](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) function, which computes the sum of all elements in an array in a single operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "print(np.sum(a)) # Will print 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629f4f9",
   "metadata": {},
   "source": [
    "**4.1** Complete the function below that computes the Euclidean norm of a vector, replacing the for-loop with `np.sum()`. You should be able to do this in a single line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_norm_vectorized(x: np.ndarray) -> float:\n",
    "    \"\"\"Compute the Euclidean norm of a vector *without* using a for loop.\n",
    "    \n",
    "    Args:\n",
    "        x: A 1D array\n",
    "    \n",
    "    Returns:\n",
    "        The Euclidean norm of the vector\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO your code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x = np.array([2, 3])\n",
    "\n",
    "    assert np.allclose(euclidean_norm_vectorized(x), euclidean_norm_slow(x)), \"result should be the same as the slow version\"\n",
    "    assert np.allclose(euclidean_norm_vectorized(x), np.sqrt(2**2 + 3**2)), \"result should be the same as manual computation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78ab4e",
   "metadata": {},
   "source": [
    "## Timing operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba6af5",
   "metadata": {},
   "source": [
    "Jupyter notebooks also provide a way to measure the time it takes to run a cell of code through a [\"magic\"](https://ipython.readthedocs.io/en/stable/interactive/magics.html) command (no, really, that's what they're actually called), which are generally prefixed with a `%`. We can use the magic command `%timeit` to compare the performance of our two implementations, which provides an estimate of the average runtime over multiple runs.\n",
    "\n",
    "**4.2** Use the cell below to time the performance of the two implementations. Approximately how many times faster is the vectorized version?\n",
    "\n",
    "**Your Response**: \n",
    "\n",
    "- average runtime of `euclidean_norm_slow(x)`: TODO\n",
    "- average runtime of `euclidean_norm_vectorized(x)`: TODO\n",
    "- speedup: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e73d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # generate a large, random vector with a million elements\n",
    "    x = np.random.randn(1000000)\n",
    "\n",
    "    # TODO run the slow version to time it, then the vectorized version\n",
    "    %timeit euclidean_norm_slow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994fd42e",
   "metadata": {},
   "source": [
    ":::{admonition} Takeaway (click this once you've completed 4.2)\n",
    ":class: dropdown\n",
    "\n",
    "The exact numbers might vary (and double check the seconds units), but you should see a ~300-500x speedup with the vectorized version!\n",
    "\n",
    "Whenever possible, we should try to use vectorized operations instead of for-loops when manipulating NumPy arrays -- though for-loops are still sometimes necessary.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565a56d",
   "metadata": {},
   "source": [
    "## Distances\n",
    "\n",
    "Finally, we can also use norms to measure the distance $d$ between two vectors. A common distance metric is the **Euclidean distance**, which is just the Euclidean norm of the difference between two vectors:\n",
    "\n",
    "$$\n",
    "d(\\vec{x}, \\vec{z}) = \\|\\vec{x} - \\vec{z}\\|_2\n",
    "$$\n",
    "\n",
    "**4.3** Using your `euclidean_norm_vectorized` function, complete the function below that computes the Euclidean distance between two vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x: np.ndarray, z: np.ndarray) -> float:\n",
    "    \"\"\"Compute the Euclidean distance between two vectors of the same dimensionality.\n",
    "    \n",
    "    Args:\n",
    "        x: A 1D array, same shape as z\n",
    "        z: A 1D array, same shape as x\n",
    "    \n",
    "    Returns:\n",
    "        The distance between the two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    assert x.shape == z.shape, \"x and z must have the same shape\"\n",
    "    \n",
    "    # TODO your code here\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = np.array([1, 2, 3])\n",
    "    z = np.array([4, 5, 6])\n",
    "    assert np.allclose(euclidean_distance(x, z), np.sqrt((1-4)**2 + (2-5)**2 + (3-6)**2)), \"result should be the same as manual computation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93820eba",
   "metadata": {},
   "source": [
    "**4.4** Is the Euclidean distance metric symmetric? That is, does $d(\\vec{x}, \\vec{z}) = d(\\vec{z}, \\vec{x})$?\n",
    "\n",
    "**Your Response**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a4f9e3",
   "metadata": {},
   "source": [
    ":::{admonition} Solution (click this to check once you've completed 4.4)\n",
    ":class: dropdown\n",
    "\n",
    "The Euclidean distance metric is symmetric -- notice how the square term in the definition of the Euclidean distance is the same regardless of which point we subtract from which:\n",
    "\n",
    "$$\n",
    "d(\\vec{x}, \\vec{z}) = \\|\\vec{x} - \\vec{z}\\|_2 = \\sqrt{\\sum_{j=1}^{p} (x_j - z_j)^2} = \\sqrt{\\sum_{j=1}^{p} (z_j - x_j)^2} = \\|\\vec{z} - \\vec{x}\\|_2 = d(\\vec{z}, \\vec{x})\n",
    "$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb281a7",
   "metadata": {},
   "source": [
    "# 5. OOP in Python with `sklearn` [1 pt]\n",
    "\n",
    "Our final topic for this worksheet is a brief introduction to object-oriented programming (OOP) in Python, which we'll explore using the [sklearn](https://scikit-learn.org/stable/) library. `sklearn` is the primary Python library for building (non-deep learning) machine learning models, and is a great example of how OOP is used in practice. Each machine learning model in `sklearn` is represented as a class, which contains the model's parameters at initailization, as well as functions for training and predicting.\n",
    "\n",
    "Let's walk through and complete the implementation of the k nearest neighbors (KNN) regressor model that we discussed in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28322d",
   "metadata": {},
   "source": [
    "## Class definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583edd4",
   "metadata": {},
   "source": [
    "Classes in Python are defined using the `class` keyword. \n",
    "\n",
    "`sklearn` provides a `BaseEstimator` class that provides a standard interface for all models, and can be **subclassed** to create new models. To extend a class, the child class just passes in the parent class name as an \"argument\" to the `class` keyword:\n",
    "\n",
    "```python\n",
    "# Our KNNRegressor class extends the BaseEstimator class\n",
    "class KNNRegressor(BaseEstimator):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f6ecc5",
   "metadata": {},
   "source": [
    "## Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6a002",
   "metadata": {},
   "source": [
    "In Python, the constructor is defined using the `__init__` method. This method is called when a new instance of the class is created. The first argument to the constructor is always `self`, which refers to the instance of the class itself -- think of it as similar to the `this` keyword in Java. \n",
    "\n",
    "Any additional arguments to the constructor are passed in by the user when the class is instantiated, and instance variables are also assigned using the `self` keyword.\n",
    "\n",
    "```python\n",
    "\n",
    "# Our KNNRegressor class extends the BaseEstimator class\n",
    "class KNNRegressor(BaseEstimator):\n",
    "    \"\"\"KNN regressor model.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_neighbors: int):\n",
    "        \"\"\"Initializes our KNNRegressor model.\n",
    "\n",
    "        Args:\n",
    "            n_neighbors: the number of neighbors to use for the KNN regressor\n",
    "        \"\"\"\n",
    "\n",
    "        # self.var_name is an instance variable that can be accessed by any method in the class\n",
    "        self.n_neighbors = n_neighbors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcaa28d",
   "metadata": {},
   "source": [
    "## Object creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f211630",
   "metadata": {},
   "source": [
    "Objects are created using the `class_name(arguments)` syntax. This should look similar to other OOP languages you may have used. For example, we can create a new KNNRegressor object with 5 neighbors as follows:\n",
    "\n",
    "```python\n",
    "\n",
    "# Create a new KNNRegressor object with 5 neighbors\n",
    "knn_model = KNNRegressor(n_neighbors=5)\n",
    "```\n",
    "\n",
    "Note that the `self` argument is not passed in. It is implicitly passed in by Python when the object is created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86551c",
   "metadata": {},
   "source": [
    "## Instance methods\n",
    "\n",
    "Instance methods are defined using the `def` keyword within the class block, and are similar to functions in Python. Like the constructor, the first argument to any instance method is **required** to be `self`.\n",
    "\n",
    "In order for our `KNNRegressor` class to be a valid `sklearn` estimator, we need to implement the `fit` and `predict` methods:\n",
    "\n",
    "```python\n",
    "class KNNRegressor(BaseEstimator):\n",
    "    ...\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        \"\"\"Fits the KNN regressor to the training data.\n",
    "\n",
    "        Note that KNN models do not have any functions or features that need to be fit, \n",
    "        so all this method does is store the training data in the instance variables.\n",
    "\n",
    "        Args:\n",
    "            X: the feature matrix of shape (n, p)\n",
    "            y: the target vector of shape (n,)\n",
    "\n",
    "        Returns:\n",
    "            self: the fitted model\n",
    "        \"\"\"\n",
    "\n",
    "        # Use self to store the training data in the instance variables\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        # sklearn fit() methods return the model itself to allow for method chaining\n",
    "        return self\n",
    "```\n",
    "\n",
    "`sklearn` uses a convention where any instance variables that are created during the model fitting process are suffixed with a `_` (e.g. `self.X_`). This is actually used by `sklearn` to determine whether a model has been fitted or not. Another convention is that sklearn `fit()` methods return the model itself to allow for method calls to be chained together, e.g. `knn_model.fit(X_train, y_train).predict(X_new)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90989dbc",
   "metadata": {},
   "source": [
    "Recall from class that the KNN regressor predicts the $y$ value of a new point by averaging the $y$ values of the `k` nearest neighbors. If $D_k = \\{(\\vec{x_1}, y_1), (\\vec{x_2}, y_2), \\ldots, (\\vec{x_k}, y_k)\\}$ is the set of $k$ nearest neighbors to a new point $\\vec{x}_{\\text{new}}$, then the prediction is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{k} \\sum_{(\\vec{x_i}, y_i) \\in D_k} y_i\n",
    "$$\n",
    "\n",
    "Let's first write a helper function, `find_k_nearest_indices`, that finds the indices of the `k` nearest neighbors to a new point $\\vec{x}$ using the Euclidean distance.\n",
    "\n",
    "The function is partially implemented below. You will need to use the [np.argsort](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) function, which returns the indices that would sort an array. For example, if we wanted to sort the array `a = np.array([3, 2, 1])`, then `np.argsort(a)` returns `[2, 1, 0]`, which are the indices that would sort `a` in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([3, 2, 1])\n",
    "print(np.argsort(a)) # Will print [2 1 0]\n",
    "print(a[np.argsort(a)]) # Will print in sorted order: [1 2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60afb4aa",
   "metadata": {},
   "source": [
    "**5.1:** Complete the function below that implements the logic described above. **Hint**: You should use the indexing and slice notation from the NumPy section to select each point in `X_train`, as well as to return the first `k` elements of the sorted array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a15a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_nearest_indices(x: np.ndarray, X_train: np.ndarray, k: int) -> list:\n",
    "    \"\"\"Finds the indices of the k nearest neighbors to a new point x.\n",
    "    \n",
    "    Args:\n",
    "        x: the new point of shape (p,)\n",
    "        X_train: the training data of shape (n, p)\n",
    "        k: the number of nearest neighbors to find\n",
    "\n",
    "    Returns:\n",
    "        the indices of the k nearest neighbors to x in X_train\n",
    "    \"\"\"\n",
    "    \n",
    "    dists = []\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        # TODO append the Euclidean distance between x and the i-th point in X\n",
    "        dists.append(None)\n",
    "    \n",
    "    # TODO call np.argsort on dists, then return the first k elements\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02760dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # initialize some simple data for testing\n",
    "    X_train = np.array([[1], \n",
    "                        [4], \n",
    "                        [6],\n",
    "                        [9]])\n",
    "\n",
    "    # test the find_k_nearest_indices function in one dimension\n",
    "    x = np.array([7]) # closest two points to 7 are 6 and 9\n",
    "    k_nearest_indices = find_k_nearest_indices(x=x, X_train=X_train, k=2)\n",
    "\n",
    "    assert np.allclose(k_nearest_indices, np.array([2, 3])), \"result should be the indices of 6 and 9, which are [2,3]\"\n",
    "\n",
    "    # Initialize some two dimensional data for testing\n",
    "    X_train = np.array([[1, 2], \n",
    "                        [2, 3], \n",
    "                        [3, 3]])\n",
    "    \n",
    "    x = np.array([0, 0]) # closest two points to (0,0) are (1,2) and (2,3)\n",
    "    k_nearest_indices = find_k_nearest_indices(x=x, X_train=X_train, k=2)\n",
    "\n",
    "    assert np.allclose(k_nearest_indices, np.array([0, 1])), \"result should be the indices of (1,2) and (2,3), which are [0,1]\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416dde9",
   "metadata": {},
   "source": [
    "**5.2:** Now, let's put things together. The `KNNRegressor` class is given below, and your job is to complete the `predict` method using the helper function you just implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae066b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from typing import Self\n",
    "\n",
    "# Our KNNRegressor class extends the BaseEstimator class\n",
    "class KNNRegressor(BaseEstimator):\n",
    "    \"\"\"KNN regressor model.\"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, n_neighbors: int):\n",
    "        \"\"\"Initializes the KNN regressor model.\n",
    "        \n",
    "        Args:\n",
    "            n_neighbors: the number of neighbors to use for the KNN regressor\n",
    "        \"\"\"\n",
    "\n",
    "        # self.var_name is an instance variable that can be accessed by any method in the class\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        \"\"\"Fits the KNN regressor to the training data.\n",
    "\n",
    "        Note that KNN models do not have any functions or features that need to be fit, \n",
    "        so all this method does is store the training data as instance variables.\n",
    "\n",
    "        Args:\n",
    "            X: the data examples of shape (n, p)\n",
    "            y: the answers vector of shape (n,)\n",
    "\n",
    "        Returns:\n",
    "            self: the fitted model\n",
    "        \"\"\"\n",
    "\n",
    "        # Use self to store the training data in the instance variables\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        # As convention, sklearn fit() methods return the model itself to allow for method chaining\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predicts the values of a set of new points X.\n",
    "\n",
    "        Args:\n",
    "            X: the new points of shape (n_new, p)\n",
    "\n",
    "        Returns:\n",
    "            the predicted values of shape (n_new,)\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.X_.shape[1] == X.shape[1], \"X must have the same number of features as the training data\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        # this loops over the rows of X\n",
    "        for x in X:\n",
    "            # TODO find the k nearest neighbors to x\n",
    "            \n",
    "\n",
    "            # TODO compute the average of the k nearest neighbors, append to predictions\n",
    "            predictions.append(None)\n",
    "\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # initialize some simple data for testing\n",
    "    X_train = np.array([[1], \n",
    "                        [4], \n",
    "                        [6],\n",
    "                        [9]])\n",
    "\n",
    "    y_train = np.array([1, 2, 3, 4])\n",
    "\n",
    "    # test the predict method\n",
    "    knn_model = KNNRegressor(n_neighbors=2)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    x = np.array([[7]]) # note that x is a 2D array of shape (1, 1)!\n",
    "    assert np.allclose(knn_model.predict(x), 3.5), \"result should be (3 + 4) / 2 = 3.5\"\n",
    "\n",
    "    # Initialize some two dimensional data for testing\n",
    "    X_train = np.array([[1, 2], \n",
    "                        [2, 3], \n",
    "                        [3, 3]])\n",
    "    \n",
    "    y_train = np.array([1, 2, 3])\n",
    "    X_new = np.array([[0, 0],  # closest two points to (0,0) are (1,2) and (2,3)\n",
    "                  [5, 5]]) # closest two points to (5,5) are (3,3) and (2,3)\n",
    "\n",
    "    knn_model = KNNRegressor(n_neighbors=2)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    assert np.allclose(knn_model.predict(X_new), np.array([1.5, 2.5])), \"result should be (1 + 2) / 2 = 1.5 and (3 + 2) / 2 = 2.5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65d24b",
   "metadata": {},
   "source": [
    "## `n_neighbors` and model \"complexity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeeecfa",
   "metadata": {},
   "source": [
    "We will frequently use interactive widgets to explore tradeoffs in building machine learning models. We will cover how to implement these widgets in a future worksheet, but for now, the code to run the widget will be provided.\n",
    "\n",
    "We will consider a simple prediction task, where our goal is to predict block-level housing prices based on a single feature: the median income of the block:\n",
    "\n",
    "- $X$ is an `(n, 1)` array of median incomes on a block, measured in tens of thousands of dollars\n",
    "- $y$ is an `(n, )` array of house prices, measured in hundreds of thousands of dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5888b",
   "metadata": {},
   "source": [
    "**5.3:** We can intuitively think of our model's \"complexity\" as how flexible its predictions are -- that is, the more \"jagged\" or \"wiggly\" the prediction curve is, the more complex the model. Run the cell below to play with how the `n_neighbors` parameter affects model complexity. Does increasing `n_neighbors` make the model more or less complex?\n",
    "\n",
    "**Your Response**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c520263",
   "metadata": {
    "tags": [
     "hide-code"
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from ws_utils import explore_n_neighbors\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "    widgets.interact_manual(explore_n_neighbors, \n",
    "        # Tells the widget to use the KNNRegressor class you just implemented\n",
    "        KNNRegressor=widgets.fixed(KNNRegressor), \n",
    "        # Creates an interactive slider for the number of neighbors\n",
    "        n_neighbors=widgets.IntSlider(value=5, min=1, max=15, step=1)\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe01900",
   "metadata": {},
   "source": [
    ":::{admonition} Takeaway (click this to check once you've completed 5.3)\n",
    ":class: dropdown\n",
    "\n",
    "You should see that decreasing `n_neighbors` makes the model more complex, as the predictions are much more jagged. This makes the model more flexible, and able to fit the data better. However, we can overdo this -- in the extreme case where `n_neighbors = 1`, the model almost perfectly fits to the training data, which may make its predictions less generalizable to new, unseen data. We will cover the tradeoffs between model complexity and generalization as we move further along in the course.\n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03e297",
   "metadata": {},
   "source": [
    "# 6. Reflection [0.5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc152f51",
   "metadata": {},
   "source": [
    "**6.1** How much time did it take you to complete this worksheet? \n",
    "\n",
    "**Your Response**: TODO\n",
    "\n",
    "**6.2** What is one thing you have a better understanding of after completing this worksheet? This could be about the concepts, the math, or the code.\n",
    "\n",
    "**Your Response**: TODO\n",
    "\n",
    "**6.3** What questions do you have about the material covered in the past week of class?\n",
    "\n",
    "**Your Response**: TODO\n",
    "\n",
    "**6.4** How comfortable do you feel about your mathematical and programming preparation for this course?\n",
    "\n",
    "**Your Response**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b2663",
   "metadata": {},
   "source": [
    ":::{admonition} How to submit\n",
    ":class: tip\n",
    "Follow the instructions on the [course website](https://comsc335.github.io/syllabus/submit.html) to submit your worksheet.\n",
    ":::\n",
    "\n",
    "Congrats on finishing the first worksheet of the course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69fe22f",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "- Some exercises are adapted from [Deisenroth 2020: Mathematics for Machine Learning](https://mml-book.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
